{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/tongpython/cat-and-dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = './cat-dog'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터 증식 : 기존의 데이터에서 약간의 변형을 갖는 새로운 데이터를 생성하는 과정입니다. 데이터 증식은 데이터의 다양성을 확보함으로써 기계학습에서 모델의 과적합을 방지하고 성능을 향상시키는 데 도움을 줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 증식(Data argumentaion)을 위해 케라스에서 제공하는 이미지 제너레이터를 사용합니다.\n",
    "이미지의 위치를 조금 옮긴다거나, 회전, 좌우반전등을 했을 때 컴퓨터가 받아들이는 이미지는 전혀 다른것이 됩니다.  \n",
    "이러한 변형을 줌으로써 학습 데이터를 늘리고, 이러한 변조에 강하게 모델을 학습시킬 수 있습니다.  \n",
    "\n",
    "- rescale은 이미지의 nomalization을 위해 사용합니다. 각 이미지별로 255로 나눈 값으로 데이터가 변형됩니다.  \n",
    "- rotation_range는 이미지의 최대 회전각을 지정합니다. 최대 20도까지 회전합니다.  \n",
    "- width,height shift_range는 이미지의 이동을 말합니다. 좌우, 위아래로 이미지의 이동하는 백분율을 지정합니다. (0.1은 10%)  \n",
    "- brightness_range는 이미지 밝기에 대한 내용입니다.  \n",
    "- horizontal_flip은 이미지의 수평 반전을 시켜줍니다.  \n",
    "    - 이 옵션의 경우 데이터셋의 이해가 필요합니다.  \n",
    "    - 예를 들면 MNIST 데이터셋의 경우 손글씨 데이터이기 때문에 수평 반전이 일어나면 안됩니다.  \n",
    "- validation_split은 검증세트의 비율을 지정해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageGenerator = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range=[.2, .2],\n",
    "    horizontal_flip=True,\n",
    "    validation_split=.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7205 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trainGen = imageGenerator.flow_from_directory(\n",
    "    os.path.join(path, 'training_set'),\n",
    "    target_size=(64, 64),\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validationGen = imageGenerator.flow_from_directory(\n",
    "    os.path.join(path, 'training_set'),\n",
    "    target_size=(64, 64),\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 8)         224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 271,466\n",
      "Trainable params: 271,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(8, 3, padding='same', activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(MaxPooling2D(2))\n",
    "#model.add(layers.Dropout(rate=0.3))\n",
    "\n",
    "model.add(Conv2D(8, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(2))\n",
    "#model.add(layers.Dropout(rate=0.3))\n",
    "\n",
    "#model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "#model.add(MaxPooling2D(2))\n",
    "#model.add(layers.Dropout(rate=0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['acc'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1441/1441 [==============================] - 479s 333ms/step - loss: 0.6137 - acc: 0.6550 - val_loss: 0.6294 - val_acc: 0.7120\n",
      "Epoch 2/5\n",
      "1441/1441 [==============================] - 849s 589ms/step - loss: 0.5526 - acc: 0.7162 - val_loss: 0.4608 - val_acc: 0.7443\n",
      "Epoch 3/5\n",
      "1441/1441 [==============================] - 357s 248ms/step - loss: 0.5199 - acc: 0.7412 - val_loss: 0.4207 - val_acc: 0.7630\n",
      "Epoch 4/5\n",
      "1441/1441 [==============================] - 354s 246ms/step - loss: 0.4963 - acc: 0.7569 - val_loss: 0.4882 - val_acc: 0.7697\n",
      "Epoch 5/5\n",
      "1440/1441 [============================>.] - ETA: 0s - loss: 0.4784 - acc: 0.7675"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "history = model.fit_generator(\n",
    "    trainGen, \n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=trainGen.samples / epochs, \n",
    "    validation_data=validationGen,\n",
    "    validation_steps=trainGen.samples / epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testGenerator = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "testGen = imageGenerator.flow_from_directory(\n",
    "    os.path.join(path, 'test_set'),\n",
    "    target_size=(64, 64),\n",
    ")\n",
    "\n",
    "model.evaluate_generator(testGen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(12, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_index = ['고양이', '개']\n",
    "\n",
    "imgs = testGen.next()\n",
    "arr = imgs[0][0]\n",
    "img = array_to_img(arr).resize((1024, 1024))\n",
    "plt.imshow(img)\n",
    "result = model.predict_classes(arr.reshape(1, 64, 64, 3))\n",
    "print('예측: {}'.format(cls_index[result[0]]))\n",
    "print('정답: {}'.format(cls_index[np.argmax(imgs[1][0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
